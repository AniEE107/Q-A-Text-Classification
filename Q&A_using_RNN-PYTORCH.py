# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ki-jmW6byHiOmJBapMqSzZvTWwlb6S9a
"""

import pandas as pd

df = pd.read_csv(r'/content/100_Unique_QA_Dataset.csv')

df.head()

#tokenize
def tokenize(text):
  text = text.lower()
  text = text.replace("?" , " ")
  text = text.replace(" ' " , " ")
  return text.split()

tokenize('What is the capital of France?')

#vocab
vocab = {'<UNK>':0}

def build_vocab(row):
  tokenized_question = tokenize(row['question'])
  tokenized_answer= tokenize(row['answer'])

  merged_tokens = tokenized_question + tokenized_answer

  for token in merged_tokens:

    if token not in vocab:
      vocab[token] = len(vocab)

df.apply(build_vocab, axis=1)

len(vocab)

#convert words to indices
def text_to_indices(text , vocab):

    indexed_text = []

    for token in tokenize(text):

      if token in vocab:
        indexed_text.append(vocab[token])
      else:
        indexed_text.append(vocab['<UNK>'])

    return indexed_text

text_to_indices("What is the capital of France" ,vocab )

import torch
from torch.utils.data import Dataset, DataLoader

class QADataset(Dataset):

  def __init__(self, df, vocab):
    self.df = df
    self.vocab = vocab

  def __len__(self):
    return self.df.shape[0]

  def __getitem__(self, index):
    numerical_question= text_to_indices(self.df.iloc[index]['question'], self.vocab)
    numerical_answer=text_to_indices(self.df.iloc[index]['answer'], self.vocab)

    return torch.tensor(numerical_question) , torch.tensor(numerical_answer)

dataset = QADataset(df, vocab)

dataset[10]

dataloader = DataLoader(dataset , batch_size=1 , shuffle=True)

for question, answer in dataloader:
  print(question , answer[0])

import torch.nn as nn

class SimpleRNN(nn.Module):

  def __init__(self , vocab_size):
    super().__init__()
    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)
    self.rnn = nn.RNN(50,64, batch_first=True)
    self.fc = nn.Linear(64 , vocab_size)

  def forward(self , question):
    embedded_quetsion = self.embedding(question)
    hidden , final = self.rnn(embedded_quetsion)
    output = self.fc(final.squeeze(0))

    return output

x = nn.Embedding(324, embedding_dim=50)
y = nn.RNN(50,64, batch_first=True)
z = nn.Linear(64,324)

a= dataset[0][0].reshape(1,6)
print("shape of a: ", a.shape)
b= x(a)
print("shape of b: ", b.shape)
c,d =y(b)
print("shape of c: ", c.shape)
print("shape of d: ", d.shape)

e=z(d.squeeze(0))

print("shape of e: ", e.shape)

learning_rate = 0.001
epochs=20

model = SimpleRNN(len(vocab))

criterion=nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)

# training loop
for epoch in range(epochs):  # 'epochs' should be a variable like epochs = 10

    total_loss = 0

    for question, answer in dataloader:

        optimizer.zero_grad()

        # Forward pass
        output = model(question)

        # If 'answer' is a list or tuple, use answer[0]; otherwise just use answer
        target = answer.view(-1).long() # Remove the extra dimension

        # Compute loss
        loss = criterion(output, target)

        # Backward pass
        loss.backward()

        # Update weights
        optimizer.step()

        total_loss += loss.item()

    print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}")

print("Output shape:", output.shape)
print("Target shape:", target.shape)

correct = 0
total = 0

# After output and target are computed
_, predicted = torch.max(output, 1)
correct += (predicted == target).sum().item()
total += target.size(0)

def predict(model, question, threshold=0.5):
    model.eval()

    # Convert question to indices
    numerical_question = text_to_indices(question, vocab)
    question_tensor = torch.tensor([numerical_question])  # batch size 1

    with torch.no_grad():
        output = model(question_tensor)
        probs = torch.nn.functional.softmax(output, dim=1)

        value, index = torch.max(probs, dim=1)
        confidence = value.item()
        pred_index = index.item()

        if confidence < threshold:
            print("I don't know (confidence too low)")
        else:
            label = index2label.get(pred_index, "<UNK>")
            print(f"Predicted: {label} (confidence: {confidence:.2f})")

predict(model, "What is the capital of France?")

list(vocab.keys())[24]

label2index = {'science': 0, 'sports': 1, 'technology': 2, 'history': 3}

index2label = {v: k for k, v in label2index.items()}

import matplotlib.pyplot as plt

def visualize_prediction(model, question, index2label):
    model.eval()
    numerical_question = text_to_indices(question, vocab)
    question_tensor = torch.tensor([numerical_question])

    with torch.no_grad():
        output = model(question_tensor)
        probs = torch.nn.functional.softmax(output, dim=1).squeeze().cpu().numpy()

    labels = [index2label.get(i, f"Class {i}") for i in range(len(probs))]

    # Plot
    plt.figure(figsize=(8, 4))
    plt.barh(labels, probs, color='skyblue')
    plt.xlabel("Confidence")
    plt.title(f"Prediction Probabilities for: \"{question}\"")
    plt.gca().invert_yaxis()
    plt.xlim(0, 1.0)
    plt.grid(axis='x')
    plt.tight_layout()
    plt.show()

visualize_prediction(model, "What is Machine?", index2label)

import matplotlib.pyplot as plt
import numpy as np

def visualize_prediction(model, question, index2label):
    model.eval()

    # Preprocess input
    numerical_question = text_to_indices(question, vocab)
    question_tensor = torch.tensor([numerical_question])

    with torch.no_grad():
        output = model(question_tensor)
        probs = torch.nn.functional.softmax(output, dim=1).squeeze().cpu().numpy()

    # Build labels safely
    labels = [index2label.get(i, f"Class {i}") for i in range(len(probs))]

    # Sort by probability
    sorted_indices = np.argsort(probs)[::-1]
    sorted_probs = probs[sorted_indices]
    sorted_labels = [labels[i] for i in sorted_indices]

    # Plot
    fig, ax = plt.subplots(figsize=(10, 5))
    bars = ax.barh(range(len(sorted_probs)), sorted_probs, color=plt.cm.viridis(sorted_probs))

    # Add text labels to bars
    for i, bar in enumerate(bars):
        ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                f"{sorted_probs[i]:.2f}", va='center', fontsize=10)

    # Configure axes
    ax.set_yticks(range(len(sorted_labels)))
    ax.set_yticklabels(sorted_labels)
    ax.invert_yaxis()
    ax.set_xlim(0, 1.0)
    ax.set_xlabel('Confidence Score')
    ax.set_title(f'Model Prediction for: "{question}"')
    plt.tight_layout()
    plt.grid(axis='x', linestyle='--', alpha=0.5)
    plt.show()

visualize_prediction(model, "What is the capital of Paris?", index2label)